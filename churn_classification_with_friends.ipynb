{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel eines Neuronalen Netzes zur Vorhersage von Kundenabwanderung\n",
    "Genutzt wird in diesem Fall ein **LSTM**-Netz (Long-Short-Term-Memory)\n",
    ", welches besonders gut für die Analyse von längeren Sequenzen (Texte, Kursverläufe etc.) geeignet ist.\n",
    "In unserem Fall sind dies Bestellverläufe verschiedener Kunden. Ziel ist es, das Netz auf einen Teil der Kundenbestellungen zu trainieren, und mit dem Rest zu testen ob das System diese richtig als abgesprungen oder nicht abgesprungen klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Wie führt man den Code aus?\n",
    "Im folgenden Dokument finden Sie Codefragmente (Zellen) und Text, der beschreibt was der Code macht. \n",
    "Die Code-Zellen müssen nacheinander von Ihnen ausgeführt werden.\n",
    "* Klicken Sie in die Zelle, um diese auszuwählen\n",
    "* Drücken Sie *Shift+Enter* um den gesamten Code der ausgewählten Zelle auszuführen. Dabei springt die Auswahl auf die nächste Zelle.\n",
    "* Um zwischen den Zellen zu springen drücken Sie *Strg+Hoch/Runter*. \n",
    "Weiter Shortcuts unter Help.\n",
    "\n",
    "Wenn Sie wenig Erfahrung mit Programmierung und Machine Learning haben wird der Code sicher schwer zu verstehen sein. Achten Sie auf die Beschreibungen und lassen Sie sich nicht Einschüchtern!\n",
    "Sie werden ein paar Einladungen zur Interaktion mit dem Code finden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die wichtigsten Bibliotheken:\n",
    "* **Keras** - Hauptframework für Machine Learning. (Basiert auf Google's Tensorflow)\n",
    "* **Numpy** - Unter anderem zur Durchführung von Vektorberechnungen.\n",
    "* **Pandas** - Regelt den Import und die Formatierung von Daten.\n",
    "* **Matplotlib** - Zur Erstellung von Diagrammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random as rn\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 40\n",
    "\n",
    "rn.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion: *Inner-Join* auf zwei Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def drop_missing_values_vise_versa(df1, df2, column_name):\n",
    "    \"\"\"Entferne die fehlenden Werte anhand einer Spalte\n",
    "    \n",
    "    Args:\n",
    "        df1 (:obj:`pandas.DataFrame`): 1. DataFrame\n",
    "        df2 (:obj:`pandas.DataFrame`): 2. DataFrame\n",
    "        column_name (:obj:`str`): relevanter Spaltenname\n",
    "    \n",
    "    Returns:\n",
    "        tuple of two :obj:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    \n",
    "    assert column_name in df1.columns and column_name in df2.columns, 'Spaltenname muss in beiden DFs vorliegen.'\n",
    "\n",
    "    drop_condition = df1[column_name].isin(df2[column_name]) == False\n",
    "    df1 = df1.drop(df1[drop_condition].index)\n",
    "\n",
    "    drop_condition = df2[column_name].isin(df1[column_name]) == False\n",
    "    df2 = df2.drop(df2[drop_condition].index)\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion: welche fehlende Daten einer Zeitreihe auffüllt. Wenn kein Wert da ist tragen wir eine 0 ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fill_dates(df, end_date):\n",
    "    \"\"\"Fülle die Zeitreihen bis zu einem gegebenen Datum auf\n",
    "    \n",
    "    Args:\n",
    "        df (:obj:`pandas.DataFrame`): DataFrame mit Zeitreihen\n",
    "        end_date (:obj:`datetime.datetime`)\n",
    "    \n",
    "    Returns:\n",
    "        :obj:`pandas.DataFrame` aufgefüllter DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    start_date = df['date'].iloc[0]\n",
    "    if start_date > end_date or len(df) == 0:\n",
    "        return df\n",
    "\n",
    "    months_diff = ((end_date.year - start_date.year) * 12 + end_date.month - start_date.month)\n",
    "    date_list = [start_date + relativedelta(months=x) for x in range(0, months_diff)]\n",
    "    date_frame = pd.DataFrame(date_list)\n",
    "    date_frame.columns = ['date']\n",
    "    value = pd.merge(date_frame, df, how='left').fillna(0)\n",
    "    value = value.drop(['date'], axis=1)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Einlesen der Daten mithilfe von **Pandas**\n",
    "* Es wird zwischen X und Y-Werten unterschieden.\n",
    "* Die X-Werte sind in unserem Fall die Bestellverläufe.\n",
    "* Der Y-Wert ist ein *boolean*-Wert, welcher besagt ob ein Kunde abgesprungen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data = pd.read_csv(\"cleaned_orders.csv\", header=0, index_col=0, sep=\",\", decimal=\".\", dtype={0:int})\n",
    "x_data['date'] = pd.to_datetime(x_data.date, format='%Y-%m-%d')\n",
    "\n",
    "x_data['date'].describe() # scope: monthly, 2015-02 until 2019-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data = pd.read_csv(\"cleaned_orders.csv\", header=0, index_col=0, sep=\",\", decimal=\".\", dtype={0:int})\n",
    "x_data['date'] = pd.to_datetime(x_data.date, format='%Y-%m-%d') # scope: monthly, 2015-02 until 2019-09\n",
    "x_data = x_data.drop(\"quantity\", axis=1)\n",
    "x_data = x_data[x_data.date < '2018-09-01'] # spätere Daten wurden zur Churn Bestimmung (y-Daten) benutzt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(\"cleaned_y_data_friends.csv\", header=0, index_col=0, sep=\",\", dtype={0:int,1:int})\n",
    "y_data = y_data.sort_values('recipient').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data, y_data = drop_missing_values_vise_versa(x_data, y_data, 'recipient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Exploration\n",
    "\n",
    "Wieviele Kunden haben wir im Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data.nunique() # Anzahl der \"unique\" Werte pro Spalte (es gibt viele Spalten pro Rezipient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie ist der Umsatz auf die Kunden verteilt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped = x_data.groupby('recipient', as_index=False)\n",
    "recipients_total_sales = grouped.agg(np.sum)\n",
    "recipients_total_sales.sort_values(by=\"sales\", ascending=False, inplace=True)\n",
    "recipients_total_sales.reset_index(inplace=True, drop=True)\n",
    "plt.plot(recipients_total_sales[\"sales\"])\n",
    "plt.xlabel(\"Kunden (sortiert)\")\n",
    "plt.ylabel(\"Summe Umsatz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sieht so aus als währen viele \"leere\" Kunden dabei. \n",
    "Schauen wir uns das genauer an. Eine log-Skala ist angebracht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recipients_total_sales[recipients_total_sales.sales == 0].count()\n",
    "plt.plot(np.log(recipients_total_sales[\"sales\"]))\n",
    "plt.xlabel(\"Kunden (sortiert)\")\n",
    "plt.ylabel(\"log Summe Umsatz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Soziale Beziehungen\n",
    "\n",
    "Wir haben für jeden Kunden die Anzahl von \"Churnern\" gezählt, die im Bekanntenkreis zu finden sind. Solche Daten könnte man aus einem sozialen Netzwerk extrahieren. Unsere Daten sind einfach generiert.\n",
    "\n",
    "Eine mögliche Hypothese ist, dass Kunden, die eine erhöhte Anzahl an Churnern im Bekanntenkreis haben, selbst eine erhöhte Churn-Wahrscheinlichkeit aufweisen.\n",
    "Wie könnte man durch einen Plot dieser Hypothese nachgehen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Hier sind Sie gefragt!**\n",
    "\n",
    "Wofür stehen wohl die Gruppen A und B? Ersetzen Sie die den Text der Labels und führen Sie die Zelle erneut aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8,4)\n",
    "\n",
    "labels=[\"Gruppe B\", \"Gruppe A\"]\n",
    "\n",
    "data = [y_data[\"churner_friends\"], y_data[\"churned\"]]\n",
    "\n",
    "ax.boxplot(data, labels=labels, vert=False)\n",
    "ax.set_xlabel(\"Number of churner friends\")\n",
    "fig.suptitle(\"Wofür stehen wohl die Gruppen A und B?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier teilen wir die Tabelle auf, weil wir als y-Daten eigentlich nur die Kundennummer und den Abwanderungstatus wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "friends = y_data.iloc[:,[0,2]]\n",
    "y_data_red = y_data.iloc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "friends.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Freunschaftsbeziehungen müssen normalisiert werden, bevor sie vom NN verarbeitet werden können!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "friends=(friends['churner_friends']-friends['churner_friends'].mean())/friends['churner_friends'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "friends.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation der gegebenen Daten\n",
    "\n",
    "Wir wollen dem Algorithmus eine Zeitreihe der Sales eines jeden Kunden übergeben. Dazu ist noch etwas Data-wrangling nötig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die drei folgenden Code-Zellen dienen der Transformation der X-Werte in ein 3D-Array, um diese für das Netzwerk lesbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data_dict =  dict()\n",
    "x_data_grouped = x_data.groupby('recipient')\n",
    "for recipient in x_data_grouped.groups:\n",
    "    x_data_dict[recipient] = pd.DataFrame(x_data_grouped['date','sales'].get_group(recipient))\n",
    "assert len(x_data_dict) == len(y_data_red) # hier testen wir ob wir gleichviele Daten für x und y haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = list()\n",
    "for key, item in x_data_dict.items():\n",
    "    X.append(fill_dates(item, datetime.strptime(\"2018-09-01\",\"%Y-%m-%d\")).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(X, value=-1,dtype='float32')\n",
    "y = np.array(y_data_red['churned'].values)\n",
    "y = y.reshape(y.shape[0],1)\n",
    "friends = friends.values.reshape(friends.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun haben wir die gewünschten Zeitreihen. Um einen besseren Eindruck zu bekommen stellen wir das einmal grafisch dar.\n",
    "\n",
    "**Verändern Sie den Wert von i** um einen anderen Kunden auszuwählen (insgesamt sind es ca 250)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotten der Umsätze eines Kunden \"i\"\n",
    "\n",
    "i = 101\n",
    "\n",
    "fig, ax = plt.subplots() # fig ist die ganze Grafik, ax ist die Oberfläche auf dem wir das Diagramm zeichnen können\n",
    "\n",
    "# Die X-Achse stellt die Zeit dar:\n",
    "timesteps = np.arange(len(X[0]))\n",
    "\n",
    "ax.bar(timesteps, X[i].flatten())\n",
    "ax.set_xlabel(\"Zeitreihe in Monaten\")\n",
    "ax.set_ylabel(\"Umsatz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trennung in Training- und Test-Daten\n",
    "\n",
    "70% Trainings- und 30% Testdaten.\n",
    "Freunschaftsbeziehungen und der zeitliche Verlauf werden als Input voneinander getrennt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_time_train, X_time_test, X_friends_train, X_friends_test, y_train, y_test = train_test_split(\n",
    "    X, friends, y, train_size=0.7, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'X_time_train: {X_time_train.shape}')\n",
    "print(f'X_time_test: {X_time_test.shape}')\n",
    "print(f'X_friends_train: {X_friends_train.shape}')\n",
    "print(f'X_friends_test: {X_friends_test.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das DL-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**An dieser Stelle sind Sie gefragt..**\n",
    "Das nachfolgende Codefragment enthält 4 modifizierbare Parameter, welche essenziell für die Genauigkeit des Netzwerks sind.\n",
    "Diese sind so initialiert, dass das Netwerk ohne Veränderung eine schlechte Performance aufweist.\n",
    "Ihre Aufgabe ist es nun diese Parameter so anzupassen, dass eine möglichst hohe Genauigkeit erzielt wird.\n",
    "\n",
    "Die Parameter sind wie folgt beschrieben:\n",
    "* **learning_rate**: Lernrate des Minimierungs-Algorithmus der Kostenfunktion (default: 0.00001, range: 0-∞)\n",
    "* **lstm_cells**: Anzahl der Memory-Cells des Netzwerks. Besitzt ein Netzwerk mehr Zellen, kann es sich eine größere Anzahl an Merkmalen merken. Zu viele können zu *Overfitting* führen. (default: 1, range: 1-∞)\n",
    "* **dropout**: Anteil der Merkmale, die zufällig gelöscht werden. Wirkt *Ovefitting* entgegen (default: 0.5, range: 0-1)\n",
    "* **epochs**: Anzahl der Traingsdurchläufe (default: 10, range: 1-∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "lstm_cells = 1\n",
    "dropout = 0.5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir testen zunächst ein Modell, dass nur die Bestellverläufe kennt. Im zweiten Modell beziehen wir dann die sozialen Beziehungen mit ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=-1, input_shape=(X_time_train.shape[1],1)))\n",
    "model.add(LSTM(lstm_cells, recurrent_dropout=dropout))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die nachfolgende Code-Zelle enthält den Aufruf der *fit*-Methode, welche das Training des Netzes mit den oben angegebenen Parametern startet. Anschließend wird eine Zusammenfassung des Traingsverlaufs ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, restore_best_weights=True, patience=5)\n",
    "history = model.fit(x=X_time_train,y=y_train,epochs=epochs, verbose=1, callbacks=[es], validation_data=(X_time_test, y_test))\n",
    "scores = model.evaluate(X_time_test, y_test, verbose=0)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 5)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Training')\n",
    "ax1.plot(history.history['val_loss'], label='Testing')\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax1.set_title(\"Training und Testing Kostenverlauf\")\n",
    "ax2.plot(history.history['acc'], label='Training')\n",
    "ax2.plot(history.history['val_acc'], label='Testing')\n",
    "ax2.legend(loc=\"upper left\")#\n",
    "ax2.set_title(\"Training und Testing Genauigkeit\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Genauigkeit: %.2f%%\" % (scores[1]*100))\n",
    "print(str(round(X_time_test.shape[0] * scores[1])) + \" von \" + str(X_time_test.shape[0]) + \" Beispielen richtig klassifiziert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun das Model, dass die sozialen Daten kennt. Vergleichen Sie die Genauigkeit und den Trainingsverlauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_time = Input(shape=(X_time_train.shape[1],1))\n",
    "input_friends = Input(shape=(X_friends_train.shape[1]))\n",
    "\n",
    "## Combined Model\n",
    "x = Masking(mask_value=-1)(input_time)\n",
    "x = LSTM(lstm_cells, recurrent_dropout=dropout)(x)\n",
    "x = Dropout(dropout)(x)\n",
    "x = concatenate([x, input_friends])\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[input_time, input_friends],\n",
    "    outputs=outputs,\n",
    "    name=\"lstm_friendship_model\",\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics=['acc'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, restore_best_weights=True, patience=5)\n",
    "history = model.fit(x=[X_time_train, X_friends_train],y=y_train,epochs=epochs, verbose=1, callbacks=[es], validation_data=([X_time_test, X_friends_test], y_test))\n",
    "scores = model.evaluate([X_time_test, X_friends_test], y_test, verbose=0)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 5)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Training')\n",
    "ax1.plot(history.history['val_loss'], label='Testing')\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax1.set_title(\"Training und Testing Kostenverlauf\")\n",
    "ax2.plot(history.history['acc'], label='Training')\n",
    "ax2.plot(history.history['val_acc'], label='Testing')\n",
    "ax2.legend(loc=\"upper left\")#\n",
    "ax2.set_title(\"Training und Testing Genauigkeit\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Genauigkeit: %.2f%%\" % (scores[1]*100))\n",
    "print(str(round(X_time_test.shape[0] * scores[1])) + \" von \" + str(X_time_test.shape[0]) + \" Beispielen richtig klassifiziert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}